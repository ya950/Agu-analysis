import requests
import pandas as pd
import json
from datetime import datetime, timedelta
import pytz
from snownlp import SnowNLP
import re
import os
from bs4 import BeautifulSoup
import feedparser
import hashlib

# è®¾ç½®æ—¶åŒº
tz = pytz.timezone('Asia/Shanghai')

class AICacheManager:
    """åˆ†æç»“æœç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir='ai_cache'):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
    
    def get_cache_key(self, data):
        """ç”Ÿæˆç¼“å­˜é”®"""
        data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(data_str.encode()).hexdigest()
    
    def get_cached_analysis(self, cache_key, max_age_hours=6):
        """è·å–ç¼“å­˜çš„åˆ†æç»“æœ"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                
                cache_time = datetime.fromisoformat(cached_data['timestamp'])
                if datetime.now() - cache_time < timedelta(hours=max_age_hours):
                    print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ (ç¼“å­˜æ—¶é—´: {cache_time})")
                    return cached_data['analysis']
                else:
                    print(f"â° ç¼“å­˜å·²è¿‡æœŸ (ç¼“å­˜æ—¶é—´: {cache_time})")
            except Exception as e:
                print(f"âŒ è¯»å–ç¼“å­˜å¤±è´¥: {e}")
        
        return None
    
    def save_analysis(self, cache_key, analysis):
        """ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        cache_data = {
            'timestamp': datetime.now().isoformat(),
            'analysis': analysis
        }
        
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ åˆ†æç»“æœå·²ç¼“å­˜")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def clean_old_cache(self, max_days=7):
        """æ¸…ç†æ—§ç¼“å­˜"""
        cutoff_time = datetime.now() - timedelta(days=max_days)
        cleaned_count = 0
        
        for filename in os.listdir(self.cache_dir):
            if filename.endswith('.json'):
                file_path = os.path.join(self.cache_dir, filename)
                try:
                    file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                    if file_time < cutoff_time:
                        os.remove(file_path)
                        cleaned_count += 1
                except Exception as e:
                    print(f"æ¸…ç†ç¼“å­˜æ–‡ä»¶å¤±è´¥ {filename}: {e}")
        
        if cleaned_count > 0:
            print(f"ğŸ§¹ å·²æ¸…ç† {cleaned_count} ä¸ªè¿‡æœŸç¼“å­˜æ–‡ä»¶")

def get_hot_stocks():
    """è·å–å½“æ—¥çƒ­é—¨è‚¡ç¥¨"""
    try:
        url = "http://push2.eastmoney.com/api/qt/clist/get"
        params = {
            'fid': 'f3', 'po': '1', 'pz': '10', 'pn': '1', 'np': '1',
            'fltt': '2', 'invt': '2',
            'fs': 'm:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23',
            'fields': 'f12,f14,f3,f62,f8,f9,f5,f6,f16,f46'
        }
        
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        if data['data'] and data['data']['diff']:
            stocks = []
            for item in data['data']['diff'][:10]:
                stocks.append({
                    'code': item['f12'],
                    'name': item['f14'],
                    'change_pct': round(item['f3'], 2),
                    'price': item['f62'],
                    'volume': item['f8'],
                    'amount': item['f9'],
                    'pe': item['f16'] if item['f16'] else 0,
                    'market_cap': item['f46'],
                    'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                })
            return stocks
    except Exception as e:
        print(f"è·å–çƒ­é—¨è‚¡ç¥¨å¤±è´¥: {str(e)}")
    return []

def get_hot_topics():
    """è·å–çƒ­é—¨è®¨è®ºè¯é¢˜"""
    topics = []
    
    # é›ªçƒçƒ­é—¨è¯é¢˜
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        url = "https://xueqiu.com/statuses/hot/list.json"
        params = {'since_id': -1, 'max_id': -1, 'count': 20}
        
        response = requests.get(url, headers=headers, params=params, timeout=10)
        data = response.json()
        
        if 'list' in data:
            for item in data['list']:
                topic = item.get('title', item.get('text', ''))[:100]
                if topic:
                    topics.append({
                        'source': 'é›ªçƒ',
                        'topic': topic,
                        'user': item.get('user', {}).get('screen_name', ''),
                        'replies': item.get('reply_count', 0),
                        'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                    })
    except Exception as e:
        print(f"è·å–é›ªçƒè¯é¢˜å¤±è´¥: {str(e)}")
    
    return topics

def analyze_sentiment(topics):
    """åˆ†æå¸‚åœºæƒ…ç»ª"""
    if not topics:
        print("âš ï¸ æ²¡æœ‰è¯é¢˜æ•°æ®ï¼Œè·³è¿‡æƒ…æ„Ÿåˆ†æ")
        return None
    
    sentiment_scores = []
    
    for topic in topics:
        try:
            s = SnowNLP(topic['topic'])
            sentiment = s.sentiments
            
            sentiment_scores.append({
                'topic': topic['topic'],
                'source': topic['source'],
                'sentiment': sentiment,
                'classification': 'positive' if sentiment > 0.6 else 'negative' if sentiment < 0.4 else 'neutral'
            })
        except Exception as e:
            print(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {str(e)}")
            sentiment_scores.append({
                'topic': topic['topic'],
                'source': topic['source'],
                'sentiment': 0.5,
                'classification': 'neutral'
            })
    
    if sentiment_scores:
        avg_sentiment = sum(s['sentiment'] for s in sentiment_scores) / len(sentiment_scores)
        
        if avg_sentiment > 0.6:
            market_effect = "èµšé’±æ•ˆåº”æ˜æ˜¾"
            effect_level = "é«˜"
        elif avg_sentiment > 0.5:
            market_effect = "è½»å¾®èµšé’±æ•ˆåº”"
            effect_level = "ä¸­"
        elif avg_sentiment > 0.4:
            market_effect = "è½»å¾®äºé’±æ•ˆåº”"
            effect_level = "ä¸­"
        else:
            market_effect = "äºé’±æ•ˆåº”æ˜æ˜¾"
            effect_level = "é«˜"
        
        return {
            'sentiment_scores': sentiment_scores,
            'avg_sentiment': round(avg_sentiment, 3),
            'market_effect': market_effect,
            'effect_level': effect_level,
            'positive_count': sum(1 for s in sentiment_scores if s['classification'] == 'positive'),
            'negative_count': sum(1 for s in sentiment_scores if s['classification'] == 'negative'),
            'neutral_count': sum(1 for s in sentiment_scores if s['classification'] == 'neutral')
        }
    
    return None

def get_hot_themes():
    """è·å–å„å¤§ç½‘ç«™çƒ­ç‚¹é¢˜æ"""
    themes = []
    
    # ä¸œæ–¹è´¢å¯Œçƒ­é—¨æ¦‚å¿µæ¿å—
    try:
        url = "http://push2.eastmoney.com/api/qt/clist/get"
        params = {
            'fid': 'f3', 'po': '1', 'pz': '20', 'pn': '1', 'np': '1',
            'fltt': '2', 'invt': '2',
            'fs': 'm:90+t:2',
            'fields': 'f12,f14,f3,f62,f136'
        }
        
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        if data['data'] and data['data']['diff']:
            for item in data['data']['diff']:
                themes.append({
                    'source': 'ä¸œæ–¹è´¢å¯Œ',
                    'theme_name': item['f14'],
                    'theme_code': item['f12'],
                    'change_pct': round(item['f3'], 2),
                    'leading_stock': item.get('f136', ''),
                    'type': 'æ¦‚å¿µæ¿å—',
                    'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                })
    except Exception as e:
        print(f"è·å–ä¸œæ–¹è´¢å¯Œçƒ­ç‚¹é¢˜æå¤±è´¥: {str(e)}")
    
    # ä»é›ªçƒè¯é¢˜ä¸­æå–é¢˜æ
    try:
        xueqiu_topics = get_hot_topics()
        
        theme_keywords = [
            'äººå·¥æ™ºèƒ½', 'AI', 'èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'æ–°èƒ½æº', 'é”‚ç”µæ± ', 'å…‰ä¼', 
            'åŒ»è¯', 'ç”Ÿç‰©', 'æ¶ˆè´¹', 'ç™½é…’', 'å†›å·¥', 'å›½ä¼æ”¹é©', 'å…ƒå®‡å®™',
            'æ•°å­—ç»æµ', 'æœºå™¨äºº', 'è‡ªåŠ¨é©¾é©¶', 'å‚¨èƒ½', 'æ°¢èƒ½', 'é£ç”µ'
        ]
        
        for topic in xueqiu_topics:
            topic_text = topic['topic']
            for keyword in theme_keywords:
                if keyword in topic_text:
                    themes.append({
                        'source': 'é›ªçƒ',
                        'theme_name': keyword,
                        'theme_code': '',
                        'change_pct': 0,
                        'leading_stock': '',
                        'type': 'è¯é¢˜é¢˜æ',
                        'original_topic': topic_text,
                        'replies': topic['replies'],
                        'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                    })
                    break
    except Exception as e:
        print(f"ä»é›ªçƒæå–é¢˜æå¤±è´¥: {str(e)}")
    
    return themes

def analyze_theme_popularity(themes, news_list):
    """åˆ†æé¢˜æçƒ­åº¦"""
    theme_stats = {}
    
    for theme in themes:
        theme_name = theme['theme_name']
        if theme_name not in theme_stats:
            theme_stats[theme_name] = {
                'count': 0, 'total_change': 0, 'sources': set(),
                'leading_stocks': set(), 'related_news': []
            }
        
        theme_stats[theme_name]['count'] += 1
        theme_stats[theme_name]['total_change'] += theme['change_pct']
        theme_stats[theme_name]['sources'].add(theme['source'])
        
        if theme['leading_stock']:
            leading_stock = str(theme['leading_stock'])
            if leading_stock.strip():
                theme_stats[theme_name]['leading_stocks'].add(leading_stock)
    
    for news in news_list:
        news_text = f"{news['title']} {news['summary']}".lower()
        for theme_name in theme_stats:
            if theme_name.lower() in news_text:
                theme_stats[theme_name]['related_news'].append({
                    'title': news['title'],
                    'source': news['source'],
                    'link': news['link']
                })
    
    theme_ranking = []
    for theme_name, stats in theme_stats.items():
        avg_change = stats['total_change'] / stats['count'] if stats['count'] > 0 else 0
        news_count = len(stats['related_news'])
        source_count = len(stats['sources'])
        
        popularity_score = (
            stats['count'] * 0.4 +
            (avg_change / 10) * 0.3 +
            news_count * 0.2 +
            source_count * 0.1
        )
        
        theme_ranking.append({
            'theme_name': theme_name,
            'popularity_score': round(popularity_score, 2),
            'count': stats['count'],
            'avg_change': round(avg_change, 2),
            'news_count': news_count,
            'source_count': source_count,
            'leading_stocks': list(stats['leading_stocks'])[:3],
            'related_news': stats['related_news'][:3]
        })
    
    theme_ranking.sort(key=lambda x: x['popularity_score'], reverse=True)
    return theme_ranking[:10]

def collect_industry_news():
    """æ”¶é›†è¡Œä¸šçƒ­ç‚¹æ–°é—»"""
    news_list = []
    
    # æ–°æµªè´¢ç»è¡Œä¸šæ–°é—»
    try:
        url = "https://rss.sina.com.cn/finance/stock/hydt.xml"
        feed = feedparser.parse(url)
        
        for entry in feed.entries[:10]:
            news_list.append({
                'title': entry.title,
                'summary': entry.summary if hasattr(entry, 'summary') else '',
                'link': entry.link,
                'published': entry.published if hasattr(entry, 'published') else '',
                'source': 'æ–°æµªè´¢ç»'
            })
    except Exception as e:
        print(f"è·å–æ–°æµªè¡Œä¸šæ–°é—»å¤±è´¥: {str(e)}")
    
    # ä¸œæ–¹è´¢å¯Œè¡Œä¸šæ–°é—»
    try:
        url = "http://finance.eastmoney.com/news/cyfj.html"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'http://finance.eastmoney.com/'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            print(f"ä¸œæ–¹è´¢å¯Œè¡Œä¸šæ–°é—»é¡µé¢è¿”å›çŠ¶æ€ç : {response.status_code}")
            return news_list
            
        soup = BeautifulSoup(response.text, 'lxml')
        
        news_items = soup.select('.list-item')[:10]
        if not news_items:
            news_items = soup.select('.news-item')[:10]
        if not news_items:
            news_items = soup.select('li')[:10]
            
        print(f"æ‰¾åˆ° {len(news_items)} æ¡æ–°é—»")
        
        for item in news_items:
            title_elem = item.select_one('.title')
            link_elem = item.select_one('a')
            time_elem = item.select_one('.time')
            
            if title_elem and link_elem:
                news_list.append({
                    'title': title_elem.get_text(strip=True),
                    'summary': '',
                    'link': link_elem['href'] if link_elem.has_attr('href') else '',
                    'published': time_elem.get_text(strip=True) if time_elem else '',
                    'source': 'ä¸œæ–¹è´¢å¯Œ'
                })
    except Exception as e:
        print(f"è·å–ä¸œæ–¹è´¢å¯Œè¡Œä¸šæ–°é—»å¤±è´¥: {str(e)}")
    
    return news_list

# ===== æ™ºèƒ½è§„åˆ™åˆ†æå‡½æ•° =====

def calculate_market_strength(hot_stocks, sentiment):
    """è®¡ç®—å¸‚åœºå¼ºåº¦æŒ‡æ ‡"""
    if not hot_stocks:
        return {'level': 'å¼±å¸‚', 'score': 3, 'features': 'ç¼ºä¹çƒ­ç‚¹'}
    
    # æ·»åŠ ç©ºå€¼æ£€æŸ¥
    if sentiment is None:
        sentiment = {'avg_sentiment': 0.5}  # ä½¿ç”¨é»˜è®¤å€¼
    
    avg_change = sum(s['change_pct'] for s in hot_stocks[:5]) / len(hot_stocks[:5])
    sentiment_score = sentiment.get('avg_sentiment', 0.5)
    
    # è®¡ç®—æˆäº¤é‡å¼ºåº¦ï¼ˆç›¸å¯¹å€¼ï¼‰
    volume_strength = sum(s['amount'] for s in hot_stocks[:5]) / 5
    volume_normalized = min(volume_strength / 1000000, 1)  # å½’ä¸€åŒ–åˆ°0-1
    
    # ç»¼åˆè¯„åˆ†è®¡ç®—
    score = (avg_change / 10) * 4 + sentiment_score * 3 + volume_normalized * 3
    
    # ç¡®å®šå¸‚åœºå¼ºåº¦ç­‰çº§
    if score >= 7:
        return {
            'level': 'å¼ºå¸‚',
            'score': round(score, 1),
            'features': 'æ™®æ¶¨æ ¼å±€ï¼Œèµ„é‡‘æ´»è·ƒï¼Œèµšé’±æ•ˆåº”æ˜æ˜¾'
        }
    elif score >= 5:
        return {
            'level': 'éœ‡è¡å¸‚',
            'score': round(score, 1),
            'features': 'ç»“æ„æ€§è¡Œæƒ…ï¼Œåˆ†åŒ–æ˜æ˜¾ï¼Œå±€éƒ¨çƒ­ç‚¹'
        }
    else:
        return {
            'level': 'å¼±å¸‚',
            'score': round(score, 1),
            'features': 'è°ƒæ•´æ ¼å±€ï¼Œè°¨æ…ä¸ºä¸»ï¼Œé˜²å¾¡ä¸ºä¸Š'
        }

def analyze_themes_deep(themes):
    """æ·±åº¦åˆ†æçƒ­ç‚¹é¢˜æ"""
    if not themes:
        return "æš‚æ— æ˜æ˜¾çƒ­ç‚¹é¢˜æï¼Œå¸‚åœºç¼ºä¹ä¸»çº¿æ–¹å‘"
    
    analysis = ""
    for i, theme in enumerate(themes[:3], 1):
        # è¯„ä¼°é¢˜ææŒç»­æ€§
        sustainability = "é«˜" if theme['popularity_score'] > 7 else "ä¸­" if theme['popularity_score'] > 4 else "ä½"
        
        # è¯„ä¼°é¢˜æåŠ¨é‡
        momentum = "å¼º" if theme['avg_change'] > 3 else "ä¸­ç­‰" if theme['avg_change'] > 0 else "å¼±"
        
        # è¯„ä¼°é¢˜æçƒ­åº¦
        heat_level = "é«˜çƒ­" if theme['popularity_score'] > 8 else "æ´»è·ƒ" if theme['popularity_score'] > 5 else "ä¸€èˆ¬"
        
        analysis += f"""
**{i}. {theme['theme_name']}**
- æŒç»­æ€§: {sustainability} | åŠ¨é‡: {momentum} | çƒ­åº¦: {heat_level}
- çƒ­åº¦è¯„åˆ†: {theme['popularity_score']} | å¹³å‡æ¶¨å¹…: {theme['avg_change']}%
- é¢†æ¶¨è‚¡: {', '.join(theme['leading_stocks'][:2]) if theme['leading_stocks'] else 'æš‚æ— é¾™å¤´'}
- å…³æ³¨åº¦: {theme['source_count']}ä¸ªå¹³å°æåŠ | {theme['news_count']}æ¡ç›¸å…³æ–°é—»

"""
    
    return analysis

def assess_risks(hot_stocks, sentiment, themes):
    """æ™ºèƒ½é£é™©è¯„ä¼°"""
    risks = []
    opportunities = []
    
    # æ·»åŠ ç©ºå€¼æ£€æŸ¥
    if sentiment is None:
        sentiment = {'avg_sentiment': 0.5}
    
    # æ£€æŸ¥æ¶¨å¹…é£é™©
    if hot_stocks:
        top_gain = hot_stocks[0]['change_pct']
        if top_gain > 8:
            risks.append("çŸ­æœŸæ¶¨å¹…è¿‡å¤§ï¼Œè·åˆ©å›åå‹åŠ›å¢åŠ ")
        elif top_gain > 5:
            risks.append("éƒ¨åˆ†ä¸ªè‚¡æ¶¨å¹…è¾ƒå¤§ï¼Œæ³¨æ„åˆ†åŒ–")
    
    # æ£€æŸ¥æƒ…ç»ªé£é™©
    sentiment_score = sentiment.get('avg_sentiment', 0.5)
    if sentiment_score > 0.8:
        risks.append("å¸‚åœºæƒ…ç»ªè¿‡çƒ­ï¼Œéœ€è­¦æƒ•å†²é«˜å›è½")
    elif sentiment_score < 0.3:
        opportunities.append("å¸‚åœºæƒ…ç»ªä½è¿·ï¼Œå¯èƒ½å­˜åœ¨è¶…è·Œæœºä¼š")
    
    # æ£€æŸ¥æˆäº¤é‡é£é™©
    if hot_stocks:
        avg_volume = sum(s['amount'] for s in hot_stocks[:5]) / 5
        if avg_volume < 500000:  # 50ä¸‡
            risks.append("æˆäº¤é‡ä¸è¶³ï¼Œä¸Šæ¶¨åŠ¨åŠ›æœ‰é™")
        elif avg_volume > 2000000:  # 200ä¸‡
            opportunities.append("æˆäº¤é‡æ´»è·ƒï¼Œå¸‚åœºå‚ä¸åº¦é«˜")
    
    # æ£€æŸ¥é¢˜æé£é™©
    if themes:
        top_theme = themes[0]
        if top_theme['popularity_score'] > 9:
            risks.append(f"{top_theme['theme_name']}é¢˜æè¿‡çƒ­ï¼Œæ³¨æ„è¿½é«˜é£é™©")
        elif top_theme['avg_change'] > 5:
            opportunities.append(f"{top_theme['theme_name']}é¢˜æåŠ¨é‡å¼ºåŠ²ï¼Œå¯æŒç»­å…³æ³¨")
    
    # ç¡®å®šé£é™©ç­‰çº§
    risk_level = "é«˜" if len(risks) >= 3 else "ä¸­" if len(risks) >= 1 else "ä½"
    
    # ä»“ä½å»ºè®®
    if risk_level == "é«˜":
        position_suggestion = "3-5æˆï¼ˆè½»ä»“é˜²å¾¡ï¼‰"
    elif risk_level == "ä¸­":
        position_suggestion = "5-7æˆï¼ˆé€‚ä¸­ä»“ä½ï¼‰"
    else:
        position_suggestion = "7-8æˆï¼ˆç§¯æå¸ƒå±€ï¼‰"
    
    return {
        'level': risk_level,
        'risks': risks,
        'opportunities': opportunities,
        'position_suggestion': position_suggestion
    }

def generate_strategy(market_strength, risk_assessment, themes):
    """ç”Ÿæˆæ“ä½œç­–ç•¥"""
    strategy = ""
    
    # åŸºäºå¸‚åœºå¼ºåº¦å’Œé£é™©çš„ç­–ç•¥
    if market_strength['level'] == 'å¼ºå¸‚' and risk_assessment['level'] == 'ä½':
        strategy = """
**ğŸ“ˆ ç§¯æè¿›æ”»ç­–ç•¥**
- ä»“ä½å»ºè®®ï¼š7-8æˆï¼Œç§¯æå‚ä¸
- é€‰è‚¡æ–¹å‘ï¼šå¼ºåŠ¿é¢˜æé¾™å¤´ï¼Œæ”¾é‡çªç ´ä¸ªè‚¡
- æ“ä½œæ–¹æ³•ï¼šé€¢ä½å¸çº³ï¼ŒæŒè‚¡å¾…æ¶¨ï¼Œé€‚å½“è¿½é«˜
- æ­¢æŸè®¾ç½®ï¼š5-8%æ­¢æŸï¼Œè®©åˆ©æ¶¦å¥”è·‘
"""
    elif market_strength['level'] == 'å¼ºå¸‚' and risk_assessment['level'] == 'ä¸­':
        strategy = """
**âš–ï¸ ç»“æ„æ€§ç­–ç•¥**
- ä»“ä½å»ºè®®ï¼š5-7æˆï¼Œç²¾é€‰ä¸ªè‚¡
- é€‰è‚¡æ–¹å‘ï¼šçƒ­ç‚¹é¢˜æè¡¥æ¶¨ï¼Œä½ä½å¯åŠ¨å“ç§
- æ“ä½œæ–¹æ³•ï¼šé«˜æŠ›ä½å¸ï¼Œæ³¢æ®µæ“ä½œï¼Œé¿å…è¿½é«˜
- æ­¢æŸè®¾ç½®ï¼š5%æ­¢æŸï¼ŒåŠæ—¶æ­¢ç›ˆ
"""
    elif market_strength['level'] == 'éœ‡è¡å¸‚':
        strategy = """
**ğŸ”„ éœ‡è¡å¸‚ç­–ç•¥**
- ä»“ä½å»ºè®®ï¼š3-5æˆï¼Œçµæ´»åº”å¯¹
- é€‰è‚¡æ–¹å‘ï¼šè¶…è·Œåå¼¹ï¼Œäº‹ä»¶é©±åŠ¨
- æ“ä½œæ–¹æ³•ï¼šå¿«è¿›å¿«å‡ºï¼Œè®¾å¥½æ­¢ç›ˆæ­¢æŸ
- æ­¢æŸè®¾ç½®ï¼š3-5%ä¸¥æ ¼æ­¢æŸ
"""
    else:
        strategy = """
**ğŸ›¡ï¸ é˜²å¾¡ç­–ç•¥**
- ä»“ä½å»ºè®®ï¼š2-3æˆï¼Œè°¨æ…è§‚æœ›
- é€‰è‚¡æ–¹å‘ï¼šé˜²å¾¡æ€§å“ç§ï¼ŒæŠ—è·Œä¸ªè‚¡
- æ“ä½œæ–¹æ³•ï¼šå¤šçœ‹å°‘åŠ¨ï¼Œç­‰å¾…ä¼ç¨³ä¿¡å·
- æ­¢æŸè®¾ç½®ï¼š3%æ­¢æŸï¼Œä¿æœ¬ç¬¬ä¸€
"""
    
    # æ·»åŠ é¢˜æå»ºè®®
    if themes:
        strategy += f"""
**ğŸ¯ é¢˜æå…³æ³¨**
é‡ç‚¹å…³æ³¨ï¼š{themes[0]['theme_name']}ã€{themes[1]['theme_name'] if len(themes) > 1 else ''}
æ“ä½œå»ºè®®ï¼šå›è°ƒä½å¸ï¼Œä¸è¿½é«˜ï¼Œè®¾å¥½æ­¢æŸ
"""
    
    return strategy

def generate_default_analysis():
    """ç”Ÿæˆé»˜è®¤åˆ†æï¼ˆå½“æ•°æ®ä¸è¶³æ—¶ï¼‰"""
    return """# ğŸ¤– æ™ºèƒ½å¸‚åœºåˆ†ææŠ¥å‘Š

## ğŸ“Š å¸‚åœºå¼ºåº¦è¯„ä¼°
**å¼ºåº¦ç­‰çº§**: æ•°æ®ä¸è¶³
**ç»¼åˆè¯„åˆ†**: 5.0/10
**ä¸»è¦ç‰¹å¾**: æ•°æ®è·å–ä¸å®Œæ•´ï¼Œå»ºè®®è°¨æ…æ“ä½œ

## ğŸ”¥ çƒ­ç‚¹é¢˜æåˆ†æ
å½“å‰æ— æ³•è·å–å®Œæ•´çš„é¢˜ææ•°æ®ï¼Œå»ºè®®ç­‰å¾…æ›´å¤šæ•°æ®ã€‚

## âš ï¸ é£é™©è¯„ä¼°
**é£é™©ç­‰çº§**: ä¸­
**ä»“ä½å»ºè®®**: 3-5æˆï¼ˆè½»ä»“è§‚æœ›ï¼‰

**ä¸»è¦é£é™©**:
- æ•°æ®è·å–ä¸å®Œæ•´ï¼Œåˆ†æå‡†ç¡®æ€§å—é™
- å»ºè®®ç­‰å¾…æ›´å®Œæ•´çš„å¸‚åœºæ•°æ®

## ğŸ¯ æ“ä½œç­–ç•¥
**è§‚æœ›ç­–ç•¥**
- å½“å‰æ•°æ®ä¸å®Œæ•´ï¼Œå»ºè®®æš‚æ—¶è§‚æœ›
- ç­‰å¾…ç³»ç»Ÿæ¢å¤æ­£å¸¸åå†åšå†³ç­–
- ä¿æŒè½»ä»“ï¼Œæ§åˆ¶é£é™©

---
*åˆ†ææ—¶é—´: {datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')} | æ™ºèƒ½è§„åˆ™å¼•æ“ç”Ÿæˆ*"""

def enhanced_rule_based_analysis(data):
    """å¢å¼ºç‰ˆæ™ºèƒ½è§„åˆ™åˆ†æ"""
    hot_stocks = data.get('hot_stocks', [])
    sentiment = data.get('sentiment_analysis', {})
    themes = data.get('theme_analysis', [])
    
    print("ğŸ§  å¼€å§‹æ™ºèƒ½è§„åˆ™åˆ†æ...")
    
    # æ·»åŠ æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
    if not hot_stocks:
        print("âš ï¸ çƒ­é—¨è‚¡ç¥¨æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åˆ†æ")
        return generate_default_analysis()
    
    # æ‰§è¡Œå„é¡¹åˆ†æ
    market_strength = calculate_market_strength(hot_stocks, sentiment)
    theme_analysis = analyze_themes_deep(themes)
    risk_assessment = assess_risks(hot_stocks, sentiment, themes)
    strategy = generate_strategy(market_strength, risk_assessment, themes)
    
    # ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š
    analysis = f"""# ğŸ¤– æ™ºèƒ½å¸‚åœºåˆ†ææŠ¥å‘Š

## ğŸ“Š å¸‚åœºå¼ºåº¦è¯„ä¼°
**å¼ºåº¦ç­‰çº§**: {market_strength['level']}
**ç»¼åˆè¯„åˆ†**: {market_strength['score']}/10
**ä¸»è¦ç‰¹å¾**: {market_strength['features']}

## ğŸ”¥ çƒ­ç‚¹é¢˜ææ·±åº¦åˆ†æ
{theme_analysis}

## âš ï¸ é£é™©è¯„ä¼°
**é£é™©ç­‰çº§**: {risk_assessment['level']}
**ä»“ä½å»ºè®®**: {risk_assessment['position_suggestion']}

**ä¸»è¦é£é™©**:
{chr(10).join(f"- {risk}" for risk in risk_assessment['risks']) if risk_assessment['risks'] else "- å½“å‰å¸‚åœºé£é™©ç›¸å¯¹å¯æ§"}

**æœºä¼šæç¤º**:
{chr(10).join(f"- {opp}" for opp in risk_assessment['opportunities']) if risk_assessment['opportunities'] else "- è€å¿ƒç­‰å¾…æ›´å¥½çš„ä»‹å…¥æ—¶æœº"}

## ğŸ¯ æ“ä½œç­–ç•¥
{strategy}

---
*åˆ†ææ—¶é—´: {datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')} | æ™ºèƒ½è§„åˆ™å¼•æ“ç”Ÿæˆ*"""
    
    print("âœ… æ™ºèƒ½è§„åˆ™åˆ†æå®Œæˆ")
    return analysis

def get_intelligent_analysis(data, cache_manager):
    """è·å–æ™ºèƒ½åˆ†æï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    print("ğŸ¤– å¼€å§‹æ™ºèƒ½åˆ†æ...")
    
    # ç”Ÿæˆç¼“å­˜é”®
    cache_key = cache_manager.get_cache_key(data)
    
    # 1. æ£€æŸ¥ç¼“å­˜
    cached_analysis = cache_manager.get_cached_analysis(cache_key)
    if cached_analysis:
        return cached_analysis
    
    # 2. ä½¿ç”¨æ™ºèƒ½è§„åˆ™åˆ†æ
    analysis_result = enhanced_rule_based_analysis(data)
    
    # 3. ä¿å­˜åˆ°ç¼“å­˜
    cache_manager.save_analysis(cache_key, analysis_result)
    
    return analysis_result

def generate_enhanced_report(hot_stocks, sentiment_analysis, theme_analysis, industry_news):
    """ç”Ÿæˆå¢å¼ºç‰ˆåˆ†ææŠ¥å‘Šï¼ˆåŒ…å«æ™ºèƒ½åˆ†æï¼‰"""
    today = datetime.now(tz).strftime('%Y-%m-%d')
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    os.makedirs('reports', exist_ok=True)
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = AICacheManager()
    
    # å®šæœŸæ¸…ç†æ—§ç¼“å­˜
    cache_manager.clean_old_cache()
    
    # å‡†å¤‡åˆ†ææ•°æ®
    analysis_data = {
        'hot_stocks': hot_stocks,
        'sentiment_analysis': sentiment_analysis,
        'theme_analysis': theme_analysis,
        'industry_news': industry_news
    }
    
    # è·å–æ™ºèƒ½åˆ†æ
    intelligent_analysis = get_intelligent_analysis(analysis_data, cache_manager)
    
    # ç”Ÿæˆå¢å¼ºç‰ˆMarkdownæŠ¥å‘Š
    md_content = f"""# Aè‚¡å¸‚åœºç»¼åˆåˆ†ææŠ¥å‘Š ({today})

> ğŸ¤– æœ¬æŠ¥å‘ŠåŒ…å«æ™ºèƒ½åˆ†æï¼Œæä¾›ä¸“ä¸šçš„å¸‚åœºæ´å¯Ÿå’Œæ“ä½œå»ºè®®

---

## ğŸ“ˆ ä»Šæ—¥çƒ­é—¨è‚¡ç¥¨TOP10

| æ’å | è‚¡ç¥¨ä»£ç  | è‚¡ç¥¨åç§° | æ¶¨è·Œå¹…(%) | æœ€æ–°ä»· | æˆäº¤é‡(æ‰‹) | æˆäº¤é¢(ä¸‡) | å¸‚ç›ˆç‡ | å¸‚å€¼(äº¿) |
|------|----------|----------|-----------|--------|------------|------------|--------|----------|
"""
    
    for i, stock in enumerate(hot_stocks, 1):
        md_content += f"| {i} | {stock['code']} | {stock['name']} | {stock['change_pct']}% | {stock['price']} | {stock['volume']:,} | {stock['amount']/10000:,.2f} | {stock['pe']} | {stock['market_cap']/100000000:,.2f} |\n"
    
    if sentiment_analysis:
        md_content += f"""
## ğŸ“Š å¸‚åœºæƒ…ç»ªåˆ†æ

### æ•´ä½“å¸‚åœºæƒ…ç»ª
- **å¹³å‡æƒ…æ„Ÿåˆ†æ•°**: {sentiment_analysis['avg_sentiment']} (0-1ï¼Œè¶Šæ¥è¿‘1è¶Šæ­£é¢)
- **å¸‚åœºæ•ˆåº”**: {sentiment_analysis['market_effect']} ({sentiment_analysis['effect_level']})
- **è¯é¢˜åˆ†å¸ƒ**: 
  - æ­£é¢: {sentiment_analysis['positive_count']} æ¡
  - ä¸­æ€§: {sentiment_analysis['neutral_count']} æ¡
  - è´Ÿé¢: {sentiment_analysis['negative_count']} æ¡

### çƒ­é—¨è¯é¢˜æƒ…æ„Ÿåˆ†æ
| è¯é¢˜æ¥æº | è¯é¢˜å†…å®¹ | æƒ…æ„Ÿåˆ†æ•° | åˆ†ç±» |
|----------|----------|----------|------|
"""
        
        for score in sentiment_analysis['sentiment_scores'][:10]:
            topic_preview = score['topic'][:50] + '...' if len(score['topic']) > 50 else score['topic']
            md_content += f"| {score['source']} | {topic_preview} | {score['sentiment']:.3f} | {score['classification']} |\n"
    
    md_content += f"""
## ğŸ”¥ çƒ­ç‚¹é¢˜æåˆ†æTOP10

| æ’å | é¢˜æåç§° | çƒ­åº¦åˆ†æ•° | å‡ºç°æ¬¡æ•° | å¹³å‡æ¶¨å¹…(%) | ç›¸å…³æ–°é—»æ•° | é¢†æ¶¨è‚¡ |
|------|----------|----------|----------|-------------|------------|--------|
"""
    
    for i, theme in enumerate(theme_analysis, 1):
        leading_stocks = ', '.join(str(stock) for stock in theme['leading_stocks'][:2]) if theme['leading_stocks'] else 'æ— '
        md_content += f"| {i} | {theme['theme_name']} | {theme['popularity_score']} | {theme['count']} | {theme['avg_change']} | {theme['news_count']} | {leading_stocks} |\n"
    
    # æ·»åŠ æ™ºèƒ½åˆ†æéƒ¨åˆ†
    md_content += f"""

---

## ğŸ¤– æ™ºèƒ½åˆ†ææŠ¥å‘Š

{intelligent_analysis}

---

## ğŸ“‹ åŸå§‹æ•°æ®è¯¦æƒ…

### çƒ­ç‚¹é¢˜æè¯¦ç»†åˆ†æ

"""
    
    for theme in theme_analysis[:5]:
        md_content += f"""
#### {theme['theme_name']} (çƒ­åº¦: {theme['popularity_score']})
- **å‡ºç°æ¬¡æ•°**: {theme['count']} æ¬¡
- **å¹³å‡æ¶¨å¹…**: {theme['avg_change']}%
- **ç›¸å…³æ–°é—»**: {theme['news_count']} æ¡
- **é¢†æ¶¨è‚¡**: {', '.join(str(stock) for stock in theme['leading_stocks']) if theme['leading_stocks'] else 'æ— '}
- **æ•°æ®æº**: {theme['source_count']} ä¸ªå¹³å°
- **ç›¸å…³æ–°é—»**:
"""
        for news in theme['related_news'][:2]:
            md_content += f"  - [{news['title']}]({news['link']}) - {news['source']}\n"
    
    md_content += f"""
### æœ€æ–°è¡Œä¸šæ–°é—»

"""
    
    for news in industry_news[:5]:
        md_content += f"""
- **{news['source']}**: [{news['title']}]({news['link']})
  - å‘å¸ƒæ—¶é—´: {news['published']}
  - æ‘˜è¦: {news['summary'][:100]}...
"""
    
    md_content += f"""

---

## ğŸ“ˆ åˆ†æè¯´æ˜

### ğŸ“Š æ•°æ®æ¥æº
- **çƒ­é—¨è‚¡ç¥¨**: ä¸œæ–¹è´¢å¯ŒAPIå®æ—¶æ•°æ®
- **å¸‚åœºæƒ…ç»ª**: é›ªçƒã€ä¸œæ–¹è´¢å¯Œè‚¡å§è¯é¢˜åˆ†æ
- **çƒ­ç‚¹é¢˜æ**: æ¦‚å¿µæ¿å—+è¯é¢˜å…³é”®è¯æå–
- **è¡Œä¸šæ–°é—»**: æ–°æµªRSSã€ä¸œæ–¹è´¢å¯Œè¡Œä¸šæ–°é—»

### ğŸ§  åˆ†ææ–¹æ³•
- **å¸‚åœºå¼ºåº¦**: ç»¼åˆæ¶¨å¹…ã€æƒ…ç»ªã€æˆäº¤é‡è®¡ç®—
- **é¢˜æè¯„ä¼°**: çƒ­åº¦ã€æŒç»­æ€§ã€åŠ¨é‡å¤šç»´åº¦åˆ†æ
- **é£é™©è¯„ä¼°**: æ¶¨å¹…ã€æƒ…ç»ªã€æˆäº¤é‡é£é™©è¯†åˆ«
- **ç­–ç•¥ç”Ÿæˆ**: åŸºäºå¸‚åœºå¼ºåº¦å’Œé£é™©çš„æ™ºèƒ½åŒ¹é…

### âš ï¸ å…è´£å£°æ˜
æœ¬æŠ¥å‘Šç”±æ™ºèƒ½è§„åˆ™å¼•æ“ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚
æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ï¼Œè¯·æ ¹æ®è‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›åšå‡ºæŠ•èµ„å†³ç­–ã€‚

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')}*
*æ™ºèƒ½åˆ†æå¼•æ“: è§„åˆ™åˆ†æ v1.0*
"""
    
    # ä¿å­˜å¢å¼ºç‰ˆæŠ¥å‘Š
    with open(f'reports/enhanced_report_{today}.md', 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    # æ›´æ–°ä¸»README
    with open('README.md', 'w', encoding='utf-8') as f:
        f.write(f"""# Aè‚¡å¸‚åœºæ™ºèƒ½åˆ†æç³»ç»Ÿ

## ğŸ¤– æ™ºèƒ½åˆ†ææŠ¥å‘Š ({today})

> ğŸš€ åŸºäºè§„åˆ™å¼•æ“çš„æ™ºèƒ½å¸‚åœºåˆ†æï¼Œæä¾›ä¸“ä¸šçš„æŠ•èµ„æ´å¯Ÿ

### ğŸ“ˆ ä»Šæ—¥çƒ­é—¨è‚¡ç¥¨TOP3
""")
        for stock in hot_stocks[:3]:
            f.write(f"- **{stock['name']} ({stock['code']})**: {stock['change_pct']}% | æˆäº¤é¢: {stock['amount']/10000:,.2f}ä¸‡\n")
        
        if sentiment_analysis:
            f.write(f"""
### ğŸ“Š å¸‚åœºæƒ…ç»ª
- **å½“å‰æ•ˆåº”**: {sentiment_analysis['market_effect']} ({sentiment_analysis['effect_level']})
- **æƒ…æ„Ÿåˆ†æ•°**: {sentiment_analysis['avg_sentiment']}
""")
        
        f.write(f"""
### ğŸ”¥ çƒ­ç‚¹é¢˜æTOP3
""")
        for theme in theme_analysis[:3]:
            f.write(f"- **{theme['theme_name']}**: çƒ­åº¦ {theme['popularity_score']} | å¹³å‡æ¶¨å¹… {theme['avg_change']}%\n")
        
        f.write(f"""
### ğŸ¤– æ™ºèƒ½åˆ†æäº®ç‚¹
- [æŸ¥çœ‹å®Œæ•´æ™ºèƒ½åˆ†ææŠ¥å‘Š](reports/enhanced_report_{today}.md)
- åŒ…å«å¸‚åœºå¼ºåº¦è¯„ä¼°ã€é£é™©åˆ†æã€æ“ä½œç­–ç•¥

### ğŸ“„ å®Œæ•´æŠ¥å‘Š
- [æ™ºèƒ½åˆ†ææŠ¥å‘Š](reports/enhanced_report_{today}.md) â­ æ¨è
- [å†å²æŠ¥å‘Šå­˜æ¡£](reports/)

### ğŸ”„ æ›´æ–°æ—¶é—´
- æ¯äº¤æ˜“æ—¥9:00å’Œ15ç‚¹è‡ªåŠ¨æ›´æ–°ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
- æœ€åæ›´æ–°: {datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')}

### ğŸ’¡ ç³»ç»Ÿç‰¹ç‚¹
- âœ… å®Œå…¨å…è´¹ï¼Œæ— éœ€APIå¯†é’¥
- âœ… æ™ºèƒ½è§„åˆ™å¼•æ“ï¼Œä¸“ä¸šåˆ†æ
- âœ… å¤šç»´åº¦é£é™©è¯„ä¼°
- âœ… ä¸ªæ€§åŒ–æ“ä½œç­–ç•¥
""")

def generate_comprehensive_report(hot_stocks, sentiment_analysis, theme_analysis):
    """ç”Ÿæˆæ ‡å‡†ç‰ˆåˆ†ææŠ¥å‘Š"""
    today = datetime.now(tz).strftime('%Y-%m-%d')
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    os.makedirs('reports', exist_ok=True)
    
    # ç”ŸæˆJSONæŠ¥å‘Š
    report = {
        'date': today,
        'hot_stocks': hot_stocks,
        'sentiment_analysis': sentiment_analysis,
        'theme_analysis': theme_analysis,
        'generated_at': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
    }
    
    with open(f'reports/comprehensive_report_{today}.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_content = f"""# Aè‚¡å¸‚åœºåˆ†ææŠ¥å‘Š ({today})

## ğŸ“ˆ ä»Šæ—¥çƒ­é—¨è‚¡ç¥¨TOP10

| æ’å | è‚¡ç¥¨ä»£ç  | è‚¡ç¥¨åç§° | æ¶¨è·Œå¹…(%) | æœ€æ–°ä»· | æˆäº¤é‡(æ‰‹) | æˆäº¤é¢(ä¸‡) | å¸‚ç›ˆç‡ | å¸‚å€¼(äº¿) |
|------|----------|----------|-----------|--------|------------|------------|--------|----------|
"""
    
    for i, stock in enumerate(hot_stocks, 1):
        md_content += f"| {i} | {stock['code']} | {stock['name']} | {stock['change_pct']}% | {stock['price']} | {stock['volume']:,} | {stock['amount']/10000:,.2f} | {stock['pe']} | {stock['market_cap']/100000000:,.2f} |\n"
    
    if sentiment_analysis:
        md_content += f"""
## ğŸ“Š å¸‚åœºæƒ…ç»ªåˆ†æ

### æ•´ä½“å¸‚åœºæƒ…ç»ª
- **å¹³å‡æƒ…æ„Ÿåˆ†æ•°**: {sentiment_analysis['avg_sentiment']} (0-1ï¼Œè¶Šæ¥è¿‘1è¶Šæ­£é¢)
- **å¸‚åœºæ•ˆåº”**: {sentiment_analysis['market_effect']} ({sentiment_analysis['effect_level']})
- **è¯é¢˜åˆ†å¸ƒ**: 
  - æ­£é¢: {sentiment_analysis['positive_count']} æ¡
  - ä¸­æ€§: {sentiment_analysis['neutral_count']} æ¡
  - è´Ÿé¢: {sentiment_analysis['negative_count']} æ¡

### çƒ­é—¨è¯é¢˜æƒ…æ„Ÿåˆ†æ
| è¯é¢˜æ¥æº | è¯é¢˜å†…å®¹ | æƒ…æ„Ÿåˆ†æ•° | åˆ†ç±» |
|----------|----------|----------|------|
"""
        
        for score in sentiment_analysis['sentiment_scores'][:10]:
            topic_preview = score['topic'][:50] + '...' if len(score['topic']) > 50 else score['topic']
            md_content += f"| {score['source']} | {topic_preview} | {score['sentiment']:.3f} | {score['classification']} |\n"
    
    md_content += f"""
## ğŸ”¥ çƒ­ç‚¹é¢˜æåˆ†æTOP10

| æ’å | é¢˜æåç§° | çƒ­åº¦åˆ†æ•° | å‡ºç°æ¬¡æ•° | å¹³å‡æ¶¨å¹…(%) | ç›¸å…³æ–°é—»æ•° | é¢†æ¶¨è‚¡ |
|------|----------|----------|----------|-------------|------------|--------|
"""
    
    for i, theme in enumerate(theme_analysis, 1):
        leading_stocks = ', '.join(str(stock) for stock in theme['leading_stocks'][:2]) if theme['leading_stocks'] else 'æ— '
        md_content += f"| {i} | {theme['theme_name']} | {theme['popularity_score']} | {theme['count']} | {theme['avg_change']} | {theme['news_count']} | {leading_stocks} |\n"
    
    md_content += f"""
### çƒ­ç‚¹é¢˜æè¯¦æƒ…

"""
    
    for theme in theme_analysis[:5]:
        md_content += f"""
#### {theme['theme_name']} (çƒ­åº¦: {theme['popularity_score']})
- **å‡ºç°æ¬¡æ•°**: {theme['count']} æ¬¡
- **å¹³å‡æ¶¨å¹…**: {theme['avg_change']}%
- **ç›¸å…³æ–°é—»**: {theme['news_count']} æ¡
- **é¢†æ¶¨è‚¡**: {', '.join(str(stock) for stock in theme['leading_stocks']) if theme['leading_stocks'] else 'æ— '}
- **ç›¸å…³æ–°é—»**:
"""
        for news in theme['related_news'][:2]:
            md_content += f"  - [{news['title']}]({news['link']}) - {news['source']}\n"
    
    md_content += f"""
---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    with open(f'reports/comprehensive_report_{today}.md', 'w', encoding='utf-8') as f:
        f.write(md_content)

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹è·å–å¸‚åœºæ•°æ®...")
    
    # 1. è·å–çƒ­é—¨è‚¡ç¥¨
    hot_stocks = get_hot_stocks()
    print(f"è·å–åˆ° {len(hot_stocks)} åªçƒ­é—¨è‚¡ç¥¨")
    
    # 2. è·å–çƒ­é—¨è¯é¢˜
    hot_topics = get_hot_topics()
    print(f"è·å–åˆ° {len(hot_topics)} æ¡çƒ­é—¨è¯é¢˜")
    
    # 3. åˆ†æå¸‚åœºæƒ…ç»ª
    sentiment_analysis = analyze_sentiment(hot_topics)
    if sentiment_analysis:
        print(f"å¸‚åœºæƒ…ç»ªåˆ†æå®Œæˆ: {sentiment_analysis['market_effect']}")
    else:
        print("å¸‚åœºæƒ…ç»ªåˆ†æå¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
    
    # 4. è·å–çƒ­ç‚¹é¢˜æ
    hot_themes = get_hot_themes()
    print(f"è·å–åˆ° {len(hot_themes)} ä¸ªçƒ­ç‚¹é¢˜æ")
    
    # 5. æ”¶é›†è¡Œä¸šæ–°é—»
    industry_news = collect_industry_news()
    print(f"è·å–åˆ° {len(industry_news)} æ¡è¡Œä¸šæ–°é—»")
    
    # 6. åˆ†æé¢˜æçƒ­åº¦
    theme_analysis = analyze_theme_popularity(hot_themes, industry_news)
    print(f"åˆ†æå®Œæˆï¼Œå‰3çƒ­é—¨é¢˜æ: {[t['theme_name'] for t in theme_analysis[:3]]}")
    
    # 7. ç”Ÿæˆæ ‡å‡†æŠ¥å‘Š
    generate_comprehensive_report(hot_stocks, sentiment_analysis, theme_analysis)
    print("æ ‡å‡†å¸‚åœºåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
    
    # 8. ç”Ÿæˆæ™ºèƒ½å¢å¼ºç‰ˆæŠ¥å‘Š
    generate_enhanced_report(hot_stocks, sentiment_analysis, theme_analysis, industry_news)
    print("æ™ºèƒ½å¢å¼ºç‰ˆå¸‚åœºåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")

if __name__ == "__main__":
    main()
