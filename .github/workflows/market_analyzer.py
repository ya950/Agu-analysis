import requests
import pandas as pd
import json
from datetime import datetime, timedelta
import pytz
from snownlp import SnowNLP
import re
import os
from bs4 import BeautifulSoup
import feedparser

# è®¾ç½®æ—¶åŒº
tz = pytz.timezone('Asia/Shanghai')

def get_hot_stocks():
    """è·å–å½“æ—¥çƒ­é—¨è‚¡ç¥¨"""
    try:
        # ä½¿ç”¨ä¸œæ–¹è´¢å¯ŒAPIè·å–æ¶¨å¹…æ¦œ
        url = "http://push2.eastmoney.com/api/qt/clist/get"
        params = {
            'fid': 'f3',  # æ¶¨å¹…
            'po': '1',    # æ’åº
            'pz': '10',   # æ¯é¡µæ•°é‡
            'pn': '1',    # é¡µç 
            'np': '1',
            'fltt': '2',
            'invt': '2',
            'fs': 'm:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23',  # Aè‚¡
            'fields': 'f12,f14,f3,f62,f8,f9,f5,f6,f16,f46'  # ä»£ç ,åç§°,æ¶¨å¹…,æœ€æ–°ä»·,æˆäº¤é‡,æˆäº¤é¢,æ˜¨æ”¶,ä»Šå¼€,å¸‚ç›ˆç‡,å¸‚å€¼
        }
        
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        if data['data'] and data['data']['diff']:
            stocks = []
            for item in data['data']['diff'][:10]:
                stocks.append({
                    'code': item['f12'],
                    'name': item['f14'],
                    'change_pct': round(item['f3'], 2),
                    'price': item['f62'],
                    'volume': item['f8'],
                    'amount': item['f9'],
                    'pe': item['f16'] if item['f16'] else 0,
                    'market_cap': item['f46'],
                    'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                })
            return stocks
    except Exception as e:
        print(f"è·å–çƒ­é—¨è‚¡ç¥¨å¤±è´¥: {str(e)}")
    return []

def get_hot_topics():
    """è·å–çƒ­é—¨è®¨è®ºè¯é¢˜"""
    topics = []
    
    # 1. é›ªçƒçƒ­é—¨è¯é¢˜
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        url = "https://xueqiu.com/statuses/hot/list.json"
        params = {
            'since_id': -1,
            'max_id': -1,
            'count': 20
        }
        
        response = requests.get(url, headers=headers, params=params, timeout=10)
        data = response.json()
        
        if 'list' in data:
            for item in data['list']:
                topic = item.get('title', item.get('text', ''))[:100]
                if topic:
                    topics.append({
                        'source': 'é›ªçƒ',
                        'topic': topic,
                        'user': item.get('user', {}).get('screen_name', ''),
                        'replies': item.get('reply_count', 0),
                        'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                    })
    except Exception as e:
        print(f"è·å–é›ªçƒè¯é¢˜å¤±è´¥: {str(e)}")
    
    # 2. ä¸œæ–¹è´¢å¯Œè‚¡å§çƒ­é—¨
    try:
        url = "http://guba.eastmoney.com/rank/api/Article/GetHotArticleList"
        params = {
            'pageSize': 10,
            'pageIndex': 1,
            'sortType': 1  # æŒ‰çƒ­åº¦æ’åº
        }
        
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        if 'data' in data and 'list' in data['data']:
            for item in data['data']['list']:
                topics.append({
                    'source': 'ä¸œæ–¹è´¢å¯Œè‚¡å§',
                    'topic': item.get('title', '')[:100],
                    'user': item.get('nickname', ''),
                    'replies': item.get('read_count', 0),
                    'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                })
    except Exception as e:
        print(f"è·å–ä¸œæ–¹è´¢å¯Œè¯é¢˜å¤±è´¥: {str(e)}")
    
    return topics

def analyze_sentiment(topics):
    """åˆ†æå¸‚åœºæƒ…ç»ª"""
    sentiment_scores = []
    
    for topic in topics:
        try:
            # ä½¿ç”¨SnowNLPè¿›è¡Œæƒ…æ„Ÿåˆ†æ
            s = SnowNLP(topic['topic'])
            sentiment = s.sentiments  # 0-1ä¹‹é—´ï¼Œè¶Šæ¥è¿‘1è¶Šæ­£é¢
            
            sentiment_scores.append({
                'topic': topic['topic'],
                'source': topic['source'],
                'sentiment': sentiment,
                'classification': 'positive' if sentiment > 0.6 else 'negative' if sentiment < 0.4 else 'neutral'
            })
        except Exception as e:
            print(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {str(e)}")
            sentiment_scores.append({
                'topic': topic['topic'],
                'source': topic['source'],
                'sentiment': 0.5,
                'classification': 'neutral'
            })
    
    # è®¡ç®—æ•´ä½“å¸‚åœºæƒ…ç»ª
    if sentiment_scores:
        avg_sentiment = sum(s['sentiment'] for s in sentiment_scores) / len(sentiment_scores)
        
        # åˆ¤æ–­å¸‚åœºæ•ˆåº”
        if avg_sentiment > 0.6:
            market_effect = "èµšé’±æ•ˆåº”æ˜æ˜¾"
            effect_level = "é«˜"
        elif avg_sentiment > 0.5:
            market_effect = "è½»å¾®èµšé’±æ•ˆåº”"
            effect_level = "ä¸­"
        elif avg_sentiment > 0.4:
            market_effect = "è½»å¾®äºé’±æ•ˆåº”"
            effect_level = "ä¸­"
        else:
            market_effect = "äºé’±æ•ˆåº”æ˜æ˜¾"
            effect_level = "é«˜"
        
        return {
            'sentiment_scores': sentiment_scores,
            'avg_sentiment': round(avg_sentiment, 3),
            'market_effect': market_effect,
            'effect_level': effect_level,
            'positive_count': sum(1 for s in sentiment_scores if s['classification'] == 'positive'),
            'negative_count': sum(1 for s in sentiment_scores if s['classification'] == 'negative'),
            'neutral_count': sum(1 for s in sentiment_scores if s['classification'] == 'neutral')
        }
    
    return None

def get_hot_themes():
    """è·å–å„å¤§ç½‘ç«™çƒ­ç‚¹é¢˜æ"""
    themes = []
    
    # 1. ä¸œæ–¹è´¢å¯Œçƒ­é—¨æ¦‚å¿µæ¿å—
    try:
        url = "http://push2.eastmoney.com/api/qt/clist/get"
        params = {
            'fid': 'f3',  # æ¶¨å¹…
            'po': '1',    # æ’åº
            'pz': '20',   # æ¯é¡µæ•°é‡
            'pn': '1',    # é¡µç 
            'np': '1',
            'fltt': '2',
            'invt': '2',
            'fs': 'm:90+t:2',  # æ¦‚å¿µæ¿å—
            'fields': 'f12,f14,f3,f62,f136'  # ä»£ç ,åç§°,æ¶¨å¹…,æœ€æ–°ä»·,é¢†æ¶¨è‚¡
        }
        
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        if data['data'] and data['data']['diff']:
            for item in data['data']['diff']:
                themes.append({
                    'source': 'ä¸œæ–¹è´¢å¯Œ',
                    'theme_name': item['f14'],
                    'theme_code': item['f12'],
                    'change_pct': round(item['f3'], 2),
                    'leading_stock': item.get('f136', ''),
                    'type': 'æ¦‚å¿µæ¿å—',
                    'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                })
    except Exception as e:
        print(f"è·å–ä¸œæ–¹è´¢å¯Œçƒ­ç‚¹é¢˜æå¤±è´¥: {str(e)}")
    
    # 2. ä»é›ªçƒè¯é¢˜ä¸­æå–é¢˜æ
    try:
        xueqiu_topics = get_hot_topics()
        
        # ä»è¯é¢˜ä¸­æå–é¢˜æå…³é”®è¯
        theme_keywords = [
            'äººå·¥æ™ºèƒ½', 'AI', 'èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'æ–°èƒ½æº', 'é”‚ç”µæ± ', 'å…‰ä¼', 
            'åŒ»è¯', 'ç”Ÿç‰©', 'æ¶ˆè´¹', 'ç™½é…’', 'å†›å·¥', 'å›½ä¼æ”¹é©', 'å…ƒå®‡å®™',
            'æ•°å­—ç»æµ', 'æœºå™¨äºº', 'è‡ªåŠ¨é©¾é©¶', 'å‚¨èƒ½', 'æ°¢èƒ½', 'é£ç”µ'
        ]
        
        for topic in xueqiu_topics:
            topic_text = topic['topic']
            for keyword in theme_keywords:
                if keyword in topic_text:
                    themes.append({
                        'source': 'é›ªçƒ',
                        'theme_name': keyword,
                        'theme_code': '',
                        'change_pct': 0,
                        'leading_stock': '',
                        'type': 'è¯é¢˜é¢˜æ',
                        'original_topic': topic_text,
                        'replies': topic['replies'],
                        'timestamp': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
                    })
                    break
    except Exception as e:
        print(f"ä»é›ªçƒæå–é¢˜æå¤±è´¥: {str(e)}")
    
    return themes

def analyze_theme_popularity(themes, news_list):
    """åˆ†æé¢˜æçƒ­åº¦"""
    theme_stats = {}
    
    # ç»Ÿè®¡å„é¢˜æå‡ºç°æ¬¡æ•°å’Œå¹³å‡æ¶¨å¹…
    for theme in themes:
        theme_name = theme['theme_name']
        if theme_name not in theme_stats:
            theme_stats[theme_name] = {
                'count': 0,
                'total_change': 0,
                'sources': set(),
                'leading_stocks': set(),
                'related_news': []
            }
        
        theme_stats[theme_name]['count'] += 1
        theme_stats[theme_name]['total_change'] += theme['change_pct']
        theme_stats[theme_name]['sources'].add(theme['source'])
        
        if theme['leading_stock']:
            theme_stats[theme_name]['leading_stocks'].add(theme['leading_stock'])
    
    # å…³è”æ–°é—»
    for news in news_list:
        news_text = f"{news['title']} {news['summary']}".lower()
        for theme_name in theme_stats:
            if theme_name.lower() in news_text:
                theme_stats[theme_name]['related_news'].append({
                    'title': news['title'],
                    'source': news['source'],
                    'link': news['link']
                })
    
    # è®¡ç®—çƒ­åº¦åˆ†æ•°
    theme_ranking = []
    for theme_name, stats in theme_stats.items():
        # çƒ­åº¦åˆ†æ•° = å‡ºç°æ¬¡æ•° * 0.4 + å¹³å‡æ¶¨å¹… * 0.3 + ç›¸å…³æ–°é—»æ•° * 0.2 + æ¥æºæ•° * 0.1
        avg_change = stats['total_change'] / stats['count'] if stats['count'] > 0 else 0
        news_count = len(stats['related_news'])
        source_count = len(stats['sources'])
        
        popularity_score = (
            stats['count'] * 0.4 +
            (avg_change / 10) * 0.3 +  # æ¶¨å¹…å½’ä¸€åŒ–
            news_count * 0.2 +
            source_count * 0.1
        )
        
        theme_ranking.append({
            'theme_name': theme_name,
            'popularity_score': round(popularity_score, 2),
            'count': stats['count'],
            'avg_change': round(avg_change, 2),
            'news_count': news_count,
            'source_count': source_count,
            'leading_stocks': list(stats['leading_stocks'])[:3],
            'related_news': stats['related_news'][:3]
        })
    
    # æŒ‰çƒ­åº¦åˆ†æ•°æ’åº
    theme_ranking.sort(key=lambda x: x['popularity_score'], reverse=True)
    
    return theme_ranking[:10]

def collect_industry_news():
    """æ”¶é›†è¡Œä¸šçƒ­ç‚¹æ–°é—»"""
    news_list = []
    
    # 1. æ–°æµªè´¢ç»è¡Œä¸šæ–°é—»
    try:
        url = "https://rss.sina.com.cn/finance/stock/hydt.xml"
        feed = feedparser.parse(url)
        
        for entry in feed.entries[:10]:
            news_list.append({
                'title': entry.title,
                'summary': entry.summary if hasattr(entry, 'summary') else '',
                'link': entry.link,
                'published': entry.published if hasattr(entry, 'published') else '',
                'source': 'æ–°æµªè´¢ç»'
            })
    except Exception as e:
        print(f"è·å–æ–°æµªè¡Œä¸šæ–°é—»å¤±è´¥: {str(e)}")
    
    # 2. ä¸œæ–¹è´¢å¯Œè¡Œä¸šæ–°é—»
    try:
        url = "http://finance.eastmoney.com/news/cyfj.html"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'lxml')
        
        news_items = soup.select('.list-item')[:10]
        
        for item in news_items:
            title_elem = item.select_one('.title')
            link_elem = item.select_one('a')
            time_elem = item.select_one('.time')
            
            if title_elem and link_elem:
                news_list.append({
                    'title': title_elem.get_text(strip=True),
                    'summary': '',
                    'link': link_elem['href'] if link_elem.has_attr('href') else '',
                    'published': time_elem.get_text(strip=True) if time_elem else '',
                    'source': 'ä¸œæ–¹è´¢å¯Œ'
                })
    except Exception as e:
        print(f"è·å–ä¸œæ–¹è´¢å¯Œè¡Œä¸šæ–°é—»å¤±è´¥: {str(e)}")
    
    return news_list

def generate_comprehensive_report(hot_stocks, sentiment_analysis, theme_analysis):
    """ç”Ÿæˆç»¼åˆå¸‚åœºåˆ†ææŠ¥å‘Š"""
    today = datetime.now(tz).strftime('%Y-%m-%d')
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    os.makedirs('reports', exist_ok=True)
    
    # ç”ŸæˆJSONæŠ¥å‘Š
    report = {
        'date': today,
        'hot_stocks': hot_stocks,
        'sentiment_analysis': sentiment_analysis,
        'theme_analysis': theme_analysis,
        'generated_at': datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
    }
    
    with open(f'reports/comprehensive_report_{today}.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_content = f"""# Aè‚¡å¸‚åœºç»¼åˆåˆ†ææŠ¥å‘Š ({today})

## ğŸ“ˆ ä»Šæ—¥çƒ­é—¨è‚¡ç¥¨TOP10

| æ’å | è‚¡ç¥¨ä»£ç  | è‚¡ç¥¨åç§° | æ¶¨è·Œå¹…(%) | æœ€æ–°ä»· | æˆäº¤é‡(æ‰‹) | æˆäº¤é¢(ä¸‡) | å¸‚ç›ˆç‡ | å¸‚å€¼(äº¿) |
|------|----------|----------|-----------|--------|------------|------------|--------|----------|
"""
    
    for i, stock in enumerate(hot_stocks, 1):
        md_content += f"| {i} | {stock['code']} | {stock['name']} | {stock['change_pct']}% | {stock['price']} | {stock['volume']:,} | {stock['amount']/10000:,.2f} | {stock['pe']} | {stock['market_cap']/100000000:,.2f} |\n"
    
    if sentiment_analysis:
        md_content += f"""
## ğŸ“Š å¸‚åœºæƒ…ç»ªåˆ†æ

### æ•´ä½“å¸‚åœºæƒ…ç»ª
- **å¹³å‡æƒ…æ„Ÿåˆ†æ•°**: {sentiment_analysis['avg_sentiment']} (0-1ï¼Œè¶Šæ¥è¿‘1è¶Šæ­£é¢)
- **å¸‚åœºæ•ˆåº”**: {sentiment_analysis['market_effect']} ({sentiment_analysis['effect_level']})
- **è¯é¢˜åˆ†å¸ƒ**: 
  - æ­£é¢: {sentiment_analysis['positive_count']} æ¡
  - ä¸­æ€§: {sentiment_analysis['neutral_count']} æ¡
  - è´Ÿé¢: {sentiment_analysis['negative_count']} æ¡

### çƒ­é—¨è¯é¢˜æƒ…æ„Ÿåˆ†æ
| è¯é¢˜æ¥æº | è¯é¢˜å†…å®¹ | æƒ…æ„Ÿåˆ†æ•° | åˆ†ç±» |
|----------|----------|----------|------|
"""
        
        for score in sentiment_analysis['sentiment_scores'][:10]:
            topic_preview = score['topic'][:50] + '...' if len(score['topic']) > 50 else score['topic']
            md_content += f"| {score['source']} | {topic_preview} | {score['sentiment']:.3f} | {score['classification']} |\n"
    
    md_content += f"""
## ğŸ”¥ çƒ­ç‚¹é¢˜æåˆ†æTOP10

| æ’å | é¢˜æåç§° | çƒ­åº¦åˆ†æ•° | å‡ºç°æ¬¡æ•° | å¹³å‡æ¶¨å¹…(%) | ç›¸å…³æ–°é—»æ•° | é¢†æ¶¨è‚¡ |
|------|----------|----------|----------|-------------|------------|--------|
"""
    
    for i, theme in enumerate(theme_analysis, 1):
        leading_stocks = ', '.join(theme['leading_stocks'][:2]) if theme['leading_stocks'] else '-'
        md_content += f"| {i} | {theme['theme_name']} | {theme['popularity_score']} | {theme['count']} | {theme['avg_change']} | {theme['news_count']} | {leading_stocks} |\n"
    
    md_content += f"""
### çƒ­ç‚¹é¢˜æè¯¦æƒ…

"""
    
    for theme in theme_analysis[:5]:
        md_content += f"""
#### {theme['theme_name']} (çƒ­åº¦: {theme['popularity_score']})
- **å‡ºç°æ¬¡æ•°**: {theme['count']} æ¬¡
- **å¹³å‡æ¶¨å¹…**: {theme['avg_change']}%
- **ç›¸å…³æ–°é—»**: {theme['news_count']} æ¡
- **é¢†æ¶¨è‚¡**: {', '.join(theme['leading_stocks']) if theme['leading_stocks'] else 'æ— '}
- **ç›¸å…³æ–°é—»**:
"""
        for news in theme['related_news'][:2]:
            md_content += f"  - [{news['title']}]({news['link']}) - {news['source']}\n"
    
    md_content += f"""
---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    with open(f'reports/comprehensive_report_{today}.md', 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    # æ›´æ–°ä¸»README
    with open('README.md', 'w', encoding='utf-8') as f:
        f.write(f"""# Aè‚¡å¸‚åœºç»¼åˆåˆ†æç³»ç»Ÿ

## ğŸ“Š æœ€æ–°å¸‚åœºæŠ¥å‘Š ({today})

### ä»Šæ—¥çƒ­é—¨è‚¡ç¥¨TOP3
""")
        for stock in hot_stocks[:3]:
            f.write(f"- **{stock['name']} ({stock['code']})**: {stock['change_pct']}% | æˆäº¤é¢: {stock['amount']/10000:,.2f}ä¸‡\n")
        
        if sentiment_analysis:
            f.write(f"""
### å¸‚åœºæƒ…ç»ª
- **å½“å‰æ•ˆåº”**: {sentiment_analysis['market_effect']} ({sentiment_analysis['effect_level']})
- **æƒ…æ„Ÿåˆ†æ•°**: {sentiment_analysis['avg_sentiment']}
""")
        
        f.write(f"""
### ğŸ”¥ çƒ­ç‚¹é¢˜æTOP3
""")
        for theme in theme_analysis[:3]:
            f.write(f"- **{theme['theme_name']}**: çƒ­åº¦ {theme['popularity_score']} | å¹³å‡æ¶¨å¹… {theme['avg_change']}%\n")
        
        f.write(f"""
### ğŸ“„ å®Œæ•´æŠ¥å‘Š
- [æŸ¥çœ‹ä»Šæ—¥å®Œæ•´æŠ¥å‘Š](reports/comprehensive_report_{today}.md)
- [å†å²æŠ¥å‘Šå­˜æ¡£](reports/)

### ğŸ”„ æ›´æ–°æ—¶é—´
- æ¯äº¤æ˜“æ—¥9:00å’Œ15ç‚¹è‡ªåŠ¨æ›´æ–°ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
- æœ€åæ›´æ–°: {datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')}
""")

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹è·å–å¸‚åœºæ•°æ®...")
    
    # 1. è·å–çƒ­é—¨è‚¡ç¥¨
    hot_stocks = get_hot_stocks()
    print(f"è·å–åˆ° {len(hot_stocks)} åªçƒ­é—¨è‚¡ç¥¨")
    
    # 2. è·å–çƒ­é—¨è¯é¢˜
    hot_topics = get_hot_topics()
    print(f"è·å–åˆ° {len(hot_topics)} æ¡çƒ­é—¨è¯é¢˜")
    
    # 3. åˆ†æå¸‚åœºæƒ…ç»ª
    sentiment_analysis = analyze_sentiment(hot_topics)
    if sentiment_analysis:
        print(f"å¸‚åœºæƒ…ç»ªåˆ†æå®Œæˆ: {sentiment_analysis['market_effect']}")
    
    # 4. è·å–çƒ­ç‚¹é¢˜æ
    hot_themes = get_hot_themes()
    print(f"è·å–åˆ° {len(hot_themes)} ä¸ªçƒ­ç‚¹é¢˜æ")
    
    # 5. æ”¶é›†è¡Œä¸šæ–°é—»
    industry_news = collect_industry_news()
    print(f"è·å–åˆ° {len(industry_news)} æ¡è¡Œä¸šæ–°é—»")
    
    # 6. åˆ†æé¢˜æçƒ­åº¦
    theme_analysis = analyze_theme_popularity(hot_themes, industry_news)
    print(f"åˆ†æå®Œæˆï¼Œå‰3çƒ­é—¨é¢˜æ: {[t['theme_name'] for t in theme_analysis[:3]]}")
    
    # 7. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    generate_comprehensive_report(hot_stocks, sentiment_analysis, theme_analysis)
    print("ç»¼åˆå¸‚åœºåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")

if __name__ == "__main__":
    main()
